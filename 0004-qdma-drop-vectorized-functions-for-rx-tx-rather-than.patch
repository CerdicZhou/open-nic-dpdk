# BSD License
#
# OpenNIC patch for Xilinx DMA IP software
#
# Copyright (c) 2016-2022 Xilinx, Inc. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without modification,
# are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name Xilinx nor the names of its contributors may be used to
#   endorse or promote products derived from this software without specific
#   prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
# ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
# ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#----------------------------------------------------------------------------------

# Dropped vectorized functions for RX-TX, rather than update for now.

diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c b/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
index e7b6ef9..f7cb66f 100644
--- a/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
@@ -40,12 +40,6 @@
 #include "qdma_rxtx.h"
 #include "qdma_devops.h"
 
-#if defined RTE_ARCH_X86_64
-#include <immintrin.h>
-#include <emmintrin.h>
-#define RTE_QDMA_DESCS_PER_LOOP (2)
-#endif //RTE_ARCH_X86_64
-
 /******** User logic dependent functions start **********/
 static int qdma_ul_extract_st_cmpt_info_v(void *ul_cmpt_entry, void *cmpt_info)
 {
@@ -59,93 +53,6 @@ static int qdma_ul_extract_st_cmpt_info_v(void *ul_cmpt_entry, void *cmpt_info)
 	return 0;
 }
 
-#ifdef QDMA_RX_VEC_X86_64
-/* Vector implementation to get packet length from two completion entries */
-static void qdma_ul_get_cmpt_pkt_len_v(void *ul_cmpt_entry, __m128i *data)
-{
-	union qdma_ul_st_cmpt_ring *cmpt_entry1, *cmpt_entry2;
-	__m128i pkt_len_shift = _mm_set_epi64x(0, 4);
-
-	cmpt_entry1 = (union qdma_ul_st_cmpt_ring *)(ul_cmpt_entry);
-	cmpt_entry2 = cmpt_entry1 + 1;
-
-	/* Read desc statuses backwards to avoid race condition */
-	/* Load a pkt desc */
-	data[1] = _mm_set_epi64x(0, cmpt_entry2->data);
-	/* Find packet length, currently driver needs
-	 * only packet length from completion info
-	 */
-	data[1] = _mm_srl_epi32(data[1], pkt_len_shift);
-
-	/* Load a pkt desc */
-	data[0] = _mm_set_epi64x(0, cmpt_entry1->data);
-	/* Find packet length, currently driver needs
-	 * only packet length from completion info
-	 */
-	data[0] = _mm_srl_epi32(data[0], pkt_len_shift);
-}
-#endif //QDMA_RX_VEC_X86_64
-
-#ifdef QDMA_TX_VEC_X86_64
-/* Vector implementation to update H2C descriptor */
-static int qdma_ul_update_st_h2c_desc_v(void *qhndl, uint64_t q_offloads,
-				struct rte_mbuf *mb)
-{
-	(void)q_offloads;
-	int nsegs = mb->nb_segs;
-	uint16_t flags = S_H2C_DESC_F_SOP | S_H2C_DESC_F_EOP;
-	uint16_t id;
-	struct qdma_ul_st_h2c_desc *tx_ring_st;
-	struct qdma_tx_queue *txq = (struct qdma_tx_queue *)qhndl;
-
-	tx_ring_st = (struct qdma_ul_st_h2c_desc *)txq->tx_ring;
-	id = txq->q_pidx_info.pidx;
-
-	if (nsegs == 1) {
-		__m128i descriptor;
-		uint16_t datalen = mb->data_len;
-
-		descriptor = _mm_set_epi64x(mb->buf_iova + mb->data_off,
-				(uint64_t)datalen << 16 |
-				(uint64_t)datalen << 32 |
-				(uint64_t)flags << 48);
-		_mm_store_si128((__m128i *)&tx_ring_st[id], descriptor);
-
-		id++;
-		if (unlikely(id >= (txq->nb_tx_desc - 1)))
-			id -= (txq->nb_tx_desc - 1);
-	} else {
-		int pkt_segs = nsegs;
-		while (nsegs && mb) {
-			__m128i descriptor;
-			uint16_t datalen = mb->data_len;
-
-			flags = 0;
-			if (nsegs == pkt_segs)
-				flags |= S_H2C_DESC_F_SOP;
-			if (nsegs == 1)
-				flags |= S_H2C_DESC_F_EOP;
-
-			descriptor = _mm_set_epi64x(mb->buf_iova + mb->data_off,
-					(uint64_t)datalen << 16 |
-					(uint64_t)datalen << 32 |
-					(uint64_t)flags << 48);
-			_mm_store_si128((__m128i *)&tx_ring_st[id], descriptor);
-
-			nsegs--;
-			mb = mb->next;
-			id++;
-			if (unlikely(id >= (txq->nb_tx_desc - 1)))
-				id -= (txq->nb_tx_desc - 1);
-		}
-	}
-
-	txq->q_pidx_info.pidx = id;
-
-	return 0;
-}
-#endif //QDMA_TX_VEC_X86_64
-
 /******** User logic dependent functions end **********/
 
 /**
@@ -836,139 +743,11 @@ struct rte_mbuf *prepare_single_packet(struct qdma_rx_queue *rxq,
 	return mb;
 }
 
-#ifdef QDMA_RX_VEC_X86_64
-/* Vector implementation to prepare mbufs for packets.
- * Update this API if HW provides more information to be populated in mbuf.
- */
-static uint16_t prepare_packets_v(struct qdma_rx_queue *rxq,
-			struct rte_mbuf **rx_pkts, uint16_t nb_pkts)
-{
-	struct rte_mbuf *mb;
-	uint16_t count = 0, count_pkts = 0;
-	uint16_t n_pkts = nb_pkts & -2;
-	uint16_t id = rxq->rx_tail;
-	struct rte_mbuf **sw_ring = rxq->sw_ring;
-	uint16_t rx_buff_size = rxq->rx_buff_size;
-	/* mask to shuffle from desc. to mbuf */
-	__m128i shuf_msk = _mm_set_epi8(
-			0xFF, 0xFF, 0xFF, 0xFF,  /* skip 32bits rss */
-			0xFF, 0xFF,      /* skip low 16 bits vlan_macip */
-			1, 0,      /* octet 0~1, 16 bits data_len */
-			0xFF, 0xFF,  /* skip high 16 bits pkt_len, zero out */
-			1, 0,      /* octet 0~1, low 16 bits pkt_len */
-			0xFF, 0xFF,  /* skip 32 bit pkt_type */
-			0xFF, 0xFF
-			);
-	__m128i mbuf_init, pktlen, zero_data;
-
-	mbuf_init = _mm_set_epi64x(0, rxq->mbuf_initializer);
-	pktlen = _mm_setzero_si128();
-	zero_data = _mm_setzero_si128();
-
-	/* compile-time check */
-	RTE_BUILD_BUG_ON(offsetof(struct rte_mbuf, pkt_len) !=
-			offsetof(struct rte_mbuf, rx_descriptor_fields1) + 4);
-	RTE_BUILD_BUG_ON(offsetof(struct rte_mbuf, data_len) !=
-			offsetof(struct rte_mbuf, rx_descriptor_fields1) + 8);
-	RTE_BUILD_BUG_ON(offsetof(struct rte_mbuf, rearm_data) !=
-			RTE_ALIGN(offsetof(struct rte_mbuf, rearm_data), 16));
-
-	for (count = 0; count < n_pkts;
-		count += RTE_QDMA_DESCS_PER_LOOP) {
-		__m128i pkt_len[RTE_QDMA_DESCS_PER_LOOP];
-		__m128i pkt_mb1, pkt_mb2;
-		__m128i mbp1;
-		uint16_t pktlen1, pktlen2;
-
-		qdma_ul_get_cmpt_pkt_len_v(
-			&rxq->cmpt_data[count], pkt_len);
-
-		pktlen1 = _mm_extract_epi16(pkt_len[0], 0);
-		pktlen2 = _mm_extract_epi16(pkt_len[1], 0);
-
-		/* Check if packets are segmented across descriptors */
-		if ((pktlen1 && (pktlen1 <= rx_buff_size)) &&
-			(pktlen2 && (pktlen2 <= rx_buff_size)) &&
-			((id + RTE_QDMA_DESCS_PER_LOOP) <
-				(rxq->nb_rx_desc - 1))) {
-			/* Load 2 (64 bit) mbuf pointers */
-			mbp1 = _mm_loadu_si128((__m128i *)&sw_ring[id]);
-
-			/* Copy 2 64 bit mbuf point into rx_pkts */
-			_mm_storeu_si128((__m128i *)&rx_pkts[count_pkts], mbp1);
-			_mm_storeu_si128((__m128i *)&sw_ring[id], zero_data);
-
-			/* Pkt 1,2 convert format from desc to pktmbuf */
-			/* We only have packet length to copy */
-			pkt_mb2 = _mm_shuffle_epi8(pkt_len[1], shuf_msk);
-			pkt_mb1 = _mm_shuffle_epi8(pkt_len[0], shuf_msk);
-
-			/* Write the rearm data and the olflags in one write */
-			_mm_store_si128(
-			(__m128i *)&rx_pkts[count_pkts]->rearm_data, mbuf_init);
-			_mm_store_si128(
-			(__m128i *)&rx_pkts[count_pkts + 1]->rearm_data,
-			mbuf_init);
-
-			/* Write packet length */
-			_mm_storeu_si128(
-			(void *)&rx_pkts[count_pkts]->rx_descriptor_fields1,
-			pkt_mb1);
-			_mm_storeu_si128(
-			(void *)&rx_pkts[count_pkts + 1]->rx_descriptor_fields1,
-			pkt_mb2);
-
-			/* Accumulate packet length counter */
-			pktlen = _mm_add_epi32(pktlen, pkt_len[0]);
-			pktlen = _mm_add_epi32(pktlen, pkt_len[1]);
-
-			count_pkts += RTE_QDMA_DESCS_PER_LOOP;
-			id += RTE_QDMA_DESCS_PER_LOOP;
-		} else {
-			/* Handle packets segmented
-			 * across multiple descriptors
-			 * or ring wrap
-			 */
-			if (pktlen1) {
-				mb = prepare_segmented_packet(rxq,
-					pktlen1, &id);
-				rx_pkts[count_pkts++] = mb;
-				pktlen = _mm_add_epi32(pktlen, pkt_len[0]);
-			}
-
-			if (pktlen2) {
-				mb = prepare_segmented_packet(rxq,
-					pktlen2, &id);
-				rx_pkts[count_pkts++] = mb;
-				pktlen = _mm_add_epi32(pktlen, pkt_len[1]);
-			}
-		}
-	}
-
-	rxq->stats.pkts += count_pkts;
-	rxq->stats.bytes += _mm_extract_epi64(pktlen, 0);
-	rxq->rx_tail = id;
-
-	/* Handle single packet, if any pending */
-	if (nb_pkts & 1) {
-		mb = prepare_single_packet(rxq, count);
-		if (mb)
-			rx_pkts[count_pkts++] = mb;
-	}
-
-	return count_pkts;
-}
-#endif //QDMA_RX_VEC_X86_64
-
 /* Prepare mbufs with packet information */
 static uint16_t prepare_packets(struct qdma_rx_queue *rxq,
 			struct rte_mbuf **rx_pkts, uint16_t nb_pkts)
 {
 	uint16_t count_pkts = 0;
-
-#ifdef QDMA_RX_VEC_X86_64
-	count_pkts = prepare_packets_v(rxq, rx_pkts, nb_pkts);
-#else //QDMA_RX_VEC_X86_64
 	struct rte_mbuf *mb;
 	uint16_t pkt_length;
 	uint16_t count = 0;
@@ -984,7 +763,6 @@ static uint16_t prepare_packets(struct qdma_rx_queue *rxq,
 		}
 		count++;
 	}
-#endif //QDMA_RX_VEC_X86_64
 
 	return count_pkts;
 }
@@ -1023,47 +801,6 @@ static int rearm_c2h_ring(struct qdma_rx_queue *rxq, uint16_t num_desc)
 		return -1;
 	}
 
-#ifdef QDMA_RX_VEC_X86_64
-	int rearm_cnt = rearm_descs & -2;
-	__m128i head_room = _mm_set_epi64x(RTE_PKTMBUF_HEADROOM,
-			RTE_PKTMBUF_HEADROOM);
-
-	for (mbuf_index = 0; mbuf_index < ((uint16_t)rearm_cnt  & 0xFFFF);
-			mbuf_index += RTE_QDMA_DESCS_PER_LOOP,
-			id += RTE_QDMA_DESCS_PER_LOOP) {
-		__m128i vaddr0, vaddr1;
-		__m128i dma_addr;
-
-		/* load buf_addr(lo 64bit) and buf_iova(hi 64bit) */
-		RTE_BUILD_BUG_ON(offsetof(struct rte_mbuf, buf_iova) !=
-				offsetof(struct rte_mbuf, buf_addr) + 8);
-
-		/* Load two mbufs data addresses */
-		vaddr0 = _mm_loadu_si128(
-				(__m128i *)&(rxq->sw_ring[id]->buf_addr));
-		vaddr1 = _mm_loadu_si128(
-				(__m128i *)&(rxq->sw_ring[id+1]->buf_addr));
-
-		/* Extract physical addresses of two mbufs */
-		dma_addr = _mm_unpackhi_epi64(vaddr0, vaddr1);
-
-		/* Add headroom to dma_addr */
-		dma_addr = _mm_add_epi64(dma_addr, head_room);
-
-		/* Write C2H desc with physical dma_addr */
-		_mm_storeu_si128((__m128i *)&rx_ring_st[id], dma_addr);
-	}
-
-	if (rearm_descs & 1) {
-		mb = rxq->sw_ring[id];
-
-		/* rearm descriptor */
-		rx_ring_st[id].dst_addr =
-				(uint64_t)mb->buf_iova +
-					RTE_PKTMBUF_HEADROOM;
-		id++;
-	}
-#else //QDMA_RX_VEC_X86_64
 	for (mbuf_index = 0; mbuf_index < rearm_descs;
 			mbuf_index++, id++) {
 		mb = rxq->sw_ring[id];
@@ -1074,7 +811,6 @@ static int rearm_c2h_ring(struct qdma_rx_queue *rxq, uint16_t num_desc)
 				(uint64_t)mb->buf_iova +
 					RTE_PKTMBUF_HEADROOM;
 	}
-#endif //QDMA_RX_VEC_X86_64
 
 	if (unlikely(id >= (rxq->nb_rx_desc - 1)))
 		id -= (rxq->nb_rx_desc - 1);
@@ -1490,11 +1226,7 @@ uint16_t qdma_xmit_pkts_st(struct qdma_tx_queue *txq, struct rte_mbuf **tx_pkts,
 		txq->sw_ring[id] = mb;
 		pkt_len += rte_pktmbuf_pkt_len(mb);
 
-#ifdef QDMA_TX_VEC_X86_64
-		ret = qdma_ul_update_st_h2c_desc_v(txq, txq->offloads, mb);
-#else
 		ret = qdma_ul_update_st_h2c_desc(txq, txq->offloads, mb);
-#endif //RTE_ARCH_X86_64
 		if (ret < 0)
 			break;
 	}
